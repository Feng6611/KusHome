---
title: "AI 提效的前提是有一定基础：blog 搭建 & 写爬虫"
author: ku
date: 2023-8-25
tags: memos
---

最近在 GPT 的帮助下尝试两件虽然门槛不算高、但我从来没有成功的事情：

- 利用 hugo + Github Page 搭建个人 blog，涉及域名配置、模板修改、工作流同步
- 在 GPT4 的帮助下写爬虫，目前只完成了一个爬取豆瓣书单 250 的项目

从开发的角度讲这两件都是很简单的事情，毕竟有大量的非技术人也能够完成。但我在 GPT 的帮助下完成后，最大的体会是：

> AI 是提效工具，并且能够大大提效；但提效的前提是有一定的基础

在做这两个尝试的过程中，我遇到过一些问题：

- 不会使用基本工具，Vscode、Github、Git 等
- 不知道一个项目是如何执行的、原理是什么、可能有哪些坑？比如 blog，不了解网页搭建的逻辑；不了解爬虫的逻辑
- 在看一个开源项目时，不知道我可能使用哪个文件下、那段代码，用在什么部分？
- 面对具体问题的时候，往往不知道如何提问。比如，爬虫，我需要 A 字段不需要 B 字段，但不知道如何告诉 GPT
- ...

因此，如果要成为 AI 加持下的多面体，你最好：

- 在一定程度上能够自己完成工作
  - 编程领域，是你需要有一定的编程基础、最好大概自己跑过类似的项目，知道目标、路径和边界。然后把具体的编程任务交给 AI
- 与 AI 有更多的沟通，尝试更多类型的项目。你可以逐渐摸清 GPT 的脾气和能力边界，更好的沟通

（以下写后发现颇为无聊，建议不看）
---

## blog 搭建

我遇到的第一个问题是：一个 blog 网页是如何搭建起来的？每一个步骤都起着什么作用？
在处理这个问题问题的过程中，有两种典型结果：

1. 纯理论，非技术人员属于是看不懂且不理解，没做过就完成留不下印象；
2. 纯步骤，问题在于无法将一个步骤与 blog 搭建建立起整体联系，可能做着做着遇到一个坑半道停下不知道如何处理（跳过 or 换方法 or 有方法处理）

不能多想，我找了一个比较信任的教程跟着做，GPT 的作用是替我解释一些操作以及解决一些特殊问题。

整体的流程大致是这样的：

1. 安装 hugo、配置模版，能够本地运行 hugo 页面
2. GithubPage 部署 & 通过域名访问
3. 模板修正 & 工作流整理

第二个问题是，到底如何使用 Git 同步数据？

到底是 Vscode 的问题，还是 Git 配置的问题，还是网络的问题？我已经不记得怎么处理的了，但困难在于很难去定位问题。

第三个问题是，域名配置的问题。

我跟着教程都配置了，却不能访问。我尝试了各种方法、等过一个晚上，都没有成功。就在我身心疲惫之际换了个方式向 GPT 提问，「所有可能的情况和 debug 方式」，后来发现是因为「ssl 加密方式」需要设置为「严格」。

第四个问题是，模板的修改以及结构对应关系。

相对比较好解决，有很完整的文档以及可以随时修改查看反馈。

整套流程下来，我大概知道了「blog 搭建」和「文章的维护更新」两个主要的逻辑和方法。但这个过程，AI 能做的并不多，最多让卡壳的部分更好突破。

## 写爬虫

分享一个他总结的提示词：

你是一个爬虫工程师，我向你提出一句话需求，按照以下结构输入完整的爬虫需求。注意，没有没有特殊强调，请按照你自己的理解给出并补全逻辑

1. 爬虫目标：

- 网站 URL（s）：（请提供您希望爬取数据的所有网页 URL）
- 爬取页面范围：（请指明需要爬取的页面数）

2. 数据需求：

- 数据字段：（请提供一个清晰的数据字段列表，描述你想要搜集哪些信息，例如标题，作者，出版日期等）
- 特殊提取规则：（如果有在特定字段中需要提取或排除信息，请明确说明）

3. 数据处理需求：

- 数据清洗：（如果需要清理噪音或冗余信息，请提供具体的规则和步骤）
- 数据格式化：（如果需要其他特定格式的数据，请说明，例如日期格式，或者去除某个字段的特定字符等）

4. 数据存储需求：

- 存储格式：（希望以何种方式存储爬取的数据，例如 CSV/JSON/XML 文件或数据库等）
- 存储路径：（希望将数据保存在哪里，或者你对输出文件的命名有什么特殊要求）

5. 优先级和排序：

- 字段排序：（如果需要对爬取的数据进行排序，指明哪个字段做为排序的标准，以及排序的方式：升序还是降序）
- 需求优先级：（如果在前述需求中，有些需求比其他更重要，请列出优先级）
